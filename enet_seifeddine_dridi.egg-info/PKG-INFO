Metadata-Version: 2.1
Name: enet_seifeddine_dridi
Version: 0.0.19
Summary: An implementation of the Enet architecture using PyTorch
Author-email: Seifeddine Dridi <seifeddine.dridi89@gmail.com>
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE

# Lane Detection

An implementation
of [ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation](https://arxiv.org/pdf/1606.02147.pdf).

# The ENet model

The model consists of 7 stages:

- Stage 0: Downsamples the input image
- Stages 1, 2, 3: encoder stages
- Stages 4, 5: decoder stages
- Transpose CNN: upsamples the output of stage 5 into the desired target size

## Install dependencies

```bash
pip3 install -r requirements.txt
```

## Crate a virtual environment

```bash
python -m venv lane_detection
```

## Activate the virtual environment

```bash
source ./venv/bin/activate
```

## Run unit tests

```bash
python3 -m unittest discover
```

## Packaging the project for distribution

```bash
python3 -m pip install --upgrade build
python3 -m build
```

Start Jupyter notebook

```bash
jupyter notebook
```

## Uploading the distribution archives

```bash
python3 -m pip install --upgrade twine
python3 -m twine upload --repository testpypi dist/*
```

## Howto

### Download the Cityscape dataset

You should already have an account. If you don't, you can request one for free from the Cityscape maintainers.

```bash
wget -v --keep-session-cookies --save-cookies=cookies.txt --post-data 'username={username}&password={password}&submit=Login' https://www.cityscapes-dataset.com/login/
```

For downloading packages:

```bash
wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=1
wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=2
wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=3
wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=4
wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=6
```

The mapping of package IDs to files:

| Id | Filename                             |
|----|--------------------------------------|
| 1  | gtFine_trainvaltest (241MB)          |
| 2  | gtCoarse.zip (1.3GB)                 |
| 3  | leftImg8bit_trainvaltest.zip (11GB)  |
| 4  | leftImg8bit_trainextra.zip (44GB)    |
| 5  | rightImg8bit_trainvaltest.zip (11GB) |
| 6  | rightImg8bit_trainextra.zip (44GB)   |
| 8  | camera_trainvaltest.zip (2MB)        |
| 9  | camera_trainextra.zip (8MB)          |
| 10 | vehicle_trainvaltest.zip (2MB)       |
| 11 | vehicle_trainextra.zip (7MB)         |

### Create the necessary directories

```bash
mkdir pretrained_model
mkdir -p datasets/cityscapes/data_unzipped/
```

### Unzip the Cityscape dataset

```bash
unzip -o datasets/cityscapes/data/gtCoarse.zip -d datasets/cityscapes/data_unzipped/
unzip -o datasets/cityscapes/data/leftImg8bit_trainvaltest.zip -d datasets/cityscapes/data_unzipped/
unzip -o datasets/cityscapes/data/leftImg8bit_trainextra.zip -d datasets/cityscapes/data_unzipped/
unzip -o datasets/cityscapes/data/rightImg8bit_trainvaltest.zip -d datasets/cityscapes/data_unzipped/
unzip -o datasets/cityscapes/data/rightImg8bit_trainextra.zip -d datasets/cityscapes/data_unzipped/
unzip -o datasets/cityscapes/data/gtFine_trainvaltest.zip -d datasets/cityscapes/data_unzipped/
```
